#!/usr/bin/env python3
"""
Script d'ex√©cution baseline (HuggingFace/PyTorch).

Am√©lioration par rapport √† la version originale :
- Option --out pour sauvegarder en JSONL
- Support des param√®tres de configuration
- Meilleure gestion des erreurs
"""

import argparse
import json
import sys
from pathlib import Path

from inference_optim_llm.engines.baseline import HFRunner
from inference_optim_llm.core.metrics import MetricsCollector


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Ex√©cution baseline avec HuggingFace transformers"
    )
    parser.add_argument(
        "--prompts-file", 
        type=Path,
        default="data/prompts.txt",
        help="Fichier contenant les prompts (un par ligne)"
    )
    parser.add_argument(
        "--out",
        type=Path,
        help="Fichier de sortie JSONL (si non sp√©cifi√©, affiche le r√©sum√© JSON)"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=1,
        help="Taille de batch"
    )
    parser.add_argument(
        "--max-new-tokens",
        type=int,
        default=64,
        help="Nombre maximum de tokens √† g√©n√©rer"
    )
    parser.add_argument(
        "--device-map",
        type=str,
        help="Strat√©gie de distribution multi-GPU (auto, balanced, etc.)"
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="Mode silencieux (pas d'affichage du r√©sum√©)"
    )
    
    args = parser.parse_args()
    
    # V√©rification du fichier de prompts
    if not args.prompts_file.exists():
        print(f"Erreur: Fichier de prompts introuvable: {args.prompts_file}", file=sys.stderr)
        sys.exit(1)
    
    # Chargement des prompts
    try:
        prompts = args.prompts_file.read_text(encoding="utf-8").strip().splitlines()
    except Exception as e:
        print(f"Erreur lors de la lecture du fichier: {e}", file=sys.stderr)
        sys.exit(1)
    
    if not prompts:
        print("Erreur: Aucun prompt trouv√© dans le fichier", file=sys.stderr)
        sys.exit(1)
    
    if not args.quiet:
        print(f"üöÄ Baseline: traitement de {len(prompts)} prompts")
    
    # Reset des m√©triques
    MetricsCollector.reset_all()
    
    # Initialisation du runner
    try:
        runner_kwargs = {
            "batch_size": args.batch_size,
            "max_new_tokens": args.max_new_tokens,
        }
        if args.device_map:
            runner_kwargs["device_map"] = args.device_map
            
        runner = HFRunner(**runner_kwargs)
    except Exception as e:
        print(f"Erreur d'initialisation: {e}", file=sys.stderr)
        sys.exit(1)
    
    # Traitement des prompts
    try:
        for i, prompt in enumerate(prompts, 1):
            runner.generate(prompt)
            if not args.quiet and i % 10 == 0:
                print(f"  Trait√© {i}/{len(prompts)} prompts")
        
        if not args.quiet:
            print("‚úÖ Traitement termin√©")
        
    except Exception as e:
        print(f"Erreur durant le traitement: {e}", file=sys.stderr)
        sys.exit(1)
    
    # Sortie des r√©sultats
    if args.out:
        # Sauvegarde en JSONL
        try:
            output_path = runner.save_metrics(args.out)
            if not args.quiet:
                print(f"üíæ M√©triques sauvegard√©es: {output_path}")
        except Exception as e:
            print(f"Erreur de sauvegarde: {e}", file=sys.stderr)
            sys.exit(1)
    else:
        # Affichage du r√©sum√© JSON
        summary = runner.metrics.summary()
        print(json.dumps(summary, indent=2, ensure_ascii=False))


if __name__ == "__main__":
    main()
