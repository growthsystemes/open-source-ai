#!/usr/bin/env python3
"""
Script de d√©marrage rapide - Installation et test en une commande.

Usage: python quick_start.py
"""

import os
import platform
import subprocess
import sys
from pathlib import Path


def detect_os():
    """D√©tecte le syst√®me d'exploitation."""
    system = platform.system().lower()
    return system


def install_dependencies_windows():
    """Installation sp√©cifique Windows."""
    print("ü™ü D√©tection Windows - Installation sp√©cialis√©e...")
    
    commands = [
        # Package principal
        ([sys.executable, "-m", "pip", "install", "-e", "."], 
         "Installation package principal"),
        
        # PyTorch CPU (plus stable sur Windows)
        ([sys.executable, "-m", "pip", "install", "torch", "torchvision", 
          "--index-url", "https://download.pytorch.org/whl/cpu"], 
         "Installation PyTorch CPU"),
         
        # Autres d√©pendances
        ([sys.executable, "-m", "pip", "install", "transformers", "typer", "rich", "huggingface-hub"], 
         "Installation utilitaires"),
    ]
    
    for cmd, desc in commands:
        print(f"üîÑ {desc}...")
        try:
            subprocess.run(cmd, check=True, capture_output=True)
            print(f"‚úÖ {desc} - OK")
        except subprocess.CalledProcessError as e:
            print(f"‚ö†Ô∏è  {desc} - Probl√®me d√©tect√©")
            if "torch" in " ".join(cmd):
                print("   üí° PyTorch peut n√©cessiter Visual C++ Redistributables")
            return False
    
    return True


def install_dependencies_unix():
    """Installation pour Linux/Mac."""
    print("üêß Installation Unix/Linux/Mac...")
    
    try:
        subprocess.run([sys.executable, "-m", "pip", "install", "-e", "."], check=True)
        subprocess.run([sys.executable, "-m", "pip", "install", "torch", "transformers", "typer", "rich"], check=True)
        print("‚úÖ D√©pendances install√©es")
        return True
    except subprocess.CalledProcessError:
        print("‚ùå √âchec installation d√©pendances")
        return False


def main():
    print("üöÄ D√©marrage rapide inference-optim-llm")
    print("=" * 50)
    
    # D√©tection OS
    os_type = detect_os()
    print(f"üñ•Ô∏è  Syst√®me d√©tect√©: {os_type}")
    
    # 1. Installation des d√©pendances selon l'OS
    print("üì¶ Installation des d√©pendances...")
    if os_type == "windows":
        install_success = install_dependencies_windows()
    else:
        install_success = install_dependencies_unix()
    
    if not install_success:
        print("‚ùå √âchec installation d√©pendances")
        if os_type == "windows":
            print("üí° Essayez: python fix_windows_setup.py")
        return False
    
    # 2. Configuration environnement
    print("\nüîß Configuration environnement...")
    env_file = Path(".env")
    if not env_file.exists():
        env_content = """MODEL_ID=gpt2
BATCH_SIZE=1
MAX_NEW_TOKENS=32
CUDA_VISIBLE_DEVICES=0
"""
        env_file.write_text(env_content)
        print("‚úÖ Fichier .env cr√©√© avec configuration de test")
    
    # 3. Test CLI adapt√© selon l'OS
    print("\nüß™ Test de l'interface CLI...")
    try:
        if os_type == "windows":
            # Test plus robuste pour Windows
            result = subprocess.run([
                sys.executable, "-c", 
                "import sys; sys.path.insert(0, '.'); "
                "try: from inference_optim_llm.cli import app; print('CLI_OK')\n"
                "except Exception as e: print(f'CLI_ERROR: {e}')"
            ], capture_output=True, text=True, timeout=15)
            
            if "CLI_OK" in result.stdout:
                print("‚úÖ CLI fonctionnel")
            elif "CLI_ERROR" in result.stdout:
                print(f"‚ö†Ô∏è  CLI partiellement fonctionnel: {result.stdout}")
                print("üí° Essayez: python fix_windows_setup.py")
            else:
                print("‚ùå CLI non testable")
                return False
        else:
            # Test standard pour Unix
            result = subprocess.run([
                sys.executable, "-m", "inference_optim_llm.cli", "--help"
            ], capture_output=True, text=True, check=True)
            print("‚úÖ CLI fonctionnel")
            
    except subprocess.CalledProcessError:
        print("‚ùå CLI non fonctionnel")
        if os_type == "windows":
            print("üí° Probl√®me PyTorch probable - Essayez: python fix_windows_setup.py")
        return False
    
    # 4. Test rapide
    print("\n‚ö° Test rapide avec GPT-2...")
    try:
        # Test tr√®s basique avec timeout
        result = subprocess.run([
            sys.executable, "-m", "inference_optim_llm.cli", "run", "baseline",
            "--prompts-file", "data/prompts.txt", "--max-new-tokens", "5", "--quiet"
        ], capture_output=True, text=True, timeout=60)
        
        if result.returncode == 0 or "baseline" in result.stderr.lower():
            print("‚úÖ Pipeline de base fonctionnel")
        else:
            print("‚ö†Ô∏è  Pipeline test√© - v√©rifiez manuellement")
    except subprocess.TimeoutExpired:
        print("‚ö†Ô∏è  Test timeout - probablement OK")
    except Exception as e:
        print(f"‚ö†Ô∏è  Test limit√©: {e}")
    
    print("\n" + "=" * 50)
    print("üéâ Setup initial termin√© !")
    print("\nüìã Commandes de test :")
    if os_type == "windows":
        print("   python quick_test_windows.py  # Test rapide Windows")
        print("   python fix_windows_setup.py   # Si probl√®me PyTorch")
    print("   python -m inference_optim_llm.cli --help")
    print("   python -m inference_optim_llm.cli run baseline")
    print("   python scripts/validate_setup.py")
    print("\nüìö Guide complet : SETUP.md")
    
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)